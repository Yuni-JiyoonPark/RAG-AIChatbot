{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing FAISS index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_9500\\213183519.py:51: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
      "  llm = OpenAI(temperature=0)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_9500\\213183519.py:62: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = qa_chain({\"question\": query, \"chat_history\": []})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:  The documents discuss the introduction of the EU's Digital Product Passport (DPP) and its implications, as well as the main contents and implications of the EU's competitiveness report. They also touch on the international financial market, including interest rates, exchange rates, and stock prices. The main focus is on recent developments and regulations related to trade in North Korea, with a special emphasis on the opinions of the author, a researcher at the Korean Development Bank.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# FAISS 저장 파일 경로\n",
    "faiss_file_path = \"./faiss_index\"\n",
    "\n",
    "# 폴더 경로 지정\n",
    "folder_path = \"./reports\"\n",
    "\n",
    "# 문서 분할 설정\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "\n",
    "# 임베딩 모델 설정\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# FAISS DB 로드 또는 생성\n",
    "if os.path.exists(faiss_file_path):\n",
    "    print(\"Loading existing FAISS index...\")\n",
    "    vector_store = FAISS.load_local(faiss_file_path, embeddings, allow_dangerous_deserialization=True)\n",
    "else:\n",
    "    print(\"FAISS index not found. Creating a new one...\")\n",
    "    # 전체 문서 저장소 초기화\n",
    "    all_docs = []\n",
    "\n",
    "    # 폴더 및 하위 폴더 내 PDF 파일 반복 처리\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file_name in files:\n",
    "            if file_name.endswith(\".pdf\"):\n",
    "                file_path = os.path.join(root, file_name)\n",
    "                print(f\"Processing file: {file_path}\")\n",
    "\n",
    "                # PDF 로더로 문서 읽기\n",
    "                loader = PyPDFLoader(file_path)\n",
    "                documents = loader.load()\n",
    "\n",
    "                # 문서 분할 및 추가\n",
    "                docs = text_splitter.split_documents(documents)\n",
    "                all_docs.extend(docs)\n",
    "\n",
    "    # 모든 문서를 벡터 저장소에 저장\n",
    "    vector_store = FAISS.from_documents(all_docs, embeddings)\n",
    "    vector_store.save_local(faiss_file_path)\n",
    "    print(f\"FAISS index saved at {faiss_file_path}\")\n",
    "\n",
    "# LLM 설정\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "# QA 체인 생성\n",
    "qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=vector_store.as_retriever(),\n",
    "    return_source_documents=True,\n",
    ")\n",
    "\n",
    "# QA 체인을 테스트하는 코드 예시\n",
    "query = \"Provide a summary of the key points in the documents.\"\n",
    "response = qa_chain({\"question\": query, \"chat_history\": []})\n",
    "\n",
    "print(\"Response:\", response[\"answer\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS 저장소가 ./faiss_index에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 생성된 FAISS 저장소를 로컬에 저장\n",
    "save_path = \"./faiss_index\"\n",
    "vector_store.save_local(save_path)\n",
    "print(f\"FAISS 저장소가 {save_path}에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "산업 은행의 2025년 예상 주요 동향은 다음과 같을 것으로 예상됩니다.\n",
      "\n",
      "1. 금리수준: 주요 중앙은행의 통화정책 기조 변화에도 상대적으로 높은 금리수준이 이어질 것으로 예상됩니다. 이는 연준과 ECB가 하반기에도 금리를 인하할 것으로 전망되지만, 금융시장 내에서는 2025년까지 팬데믹 이전보다 높은 금리수준을 유지할 것으로 예상됩니다. 이러한 상황에서 산업 은행은 금리 변동에 대비하고 자산 및 부채 구조를 최적화하는 전략을 마련해야 할 것입니다.\n",
      "\n",
      "2. 부동산 시장: 높은 금리수준의 지속으로 인해 미국과 유로존의 상업용 부동산 가격이 하락할 것으로 예상됩니다. 이에 따라 산업 은행은 부동산 관련 자산의 가치 하락에 대비하고 부실 장기화 및 심화 우려를 줄이기 위한 대책을 마련해야 할 것입니다.\n",
      "\n",
      "3. 신용 건전성: 가계 및 기업의 신용 건전성이 저하될 가능성이 있습니다. 이에 따라 산업 은행은 NPL비율이 증가할 것으로 예상되는 상황에서 적시에 대책을 마련하여 신용 위험을 최소화해야 할 것입니다.\n",
      "\n",
      "4. 중국의 제조업 발전: 중국의 2025년 제조업 발전을 위한 8대 지원방안과 주요 내용을 고려할 때, 산업 은행은 중국 제조업 기업들에 대한 금융 지원을 강화하고, 제조업 발전에 적합한 보험 상품과 서비스를 개발하여 지원해야 할 것입니다. 또한, 중국의 시스템 개혁과 공정 경쟁 시장환경 조성에 따라 산업 은행은 적시에 조치를 취하여 중국 시장에서의 경쟁력을 강화해야 할 것입니다.\n",
      "\n",
      "이러한 주요 동향을 고려하여 산업 은행은 미래에 대비한 전략을 세우고 적극적으로 대응해야 할 것입니다. 이를 통해 안정적인 성장과 수익을 유지하고 위험을 최소화할 수 있을 것입니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "# LLM 초기화\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "# 사용자 정의 프롬프트 템플릿\n",
    "custom_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\", \"history\"],\n",
    "    template=(\n",
    "        \"다음은 문서에서 추출한 관련 정보입니다:\\n\\n{context}\\n\\n\"\n",
    "        \"이전에 나눈 대화는 다음과 같습니다:\\n{history}\\n\\n\"\n",
    "        \"위의 정보와 대화를 바탕으로, 아래 질문에 대해 깊이 있고 상세한 답변을 작성해 주세요.\\n\"\n",
    "        \"가능한 경우, 구체적인 예시와 설명을 추가하고, 관련 배경 지식도 포함해 주세요.\\n\\n\"\n",
    "        \"질문: {question}\\n\\n\"\n",
    "        \"상세하고 분석적인 답변:\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# QA 체인 생성\n",
    "qa_chain = create_stuff_documents_chain(llm, custom_prompt)\n",
    "\n",
    "# 사용자 질문 처리\n",
    "query = \"산업 은행의 2025년 예상 주요 동향\"\n",
    "\n",
    "# 유사 문서 검색\n",
    "retrieved_docs = vector_store.similarity_search(query, k=5)\n",
    "\n",
    "# 검색된 문서를 Document 객체로 변환 (page_content를 문자열로 설정)\n",
    "documents = [\n",
    "    Document(page_content=doc.page_content if hasattr(doc, 'page_content') else str(doc), metadata=doc.metadata)\n",
    "    for doc in retrieved_docs\n",
    "]\n",
    "\n",
    "# 히스토리 초기화\n",
    "history = []\n",
    "\n",
    "# 히스토리를 문자열로 생성\n",
    "history_text = \"\\n\".join(\n",
    "    [f\"Q: {entry['question']}\\nA: {entry['answer']}\" for entry in history]\n",
    ")\n",
    "\n",
    "# 응답 생성\n",
    "response = qa_chain.invoke({\n",
    "    \"context\": documents,\n",
    "    \"question\": query,\n",
    "    \"history\": history_text\n",
    "})\n",
    "\n",
    "# 출력\n",
    "print(response)\n",
    "\n",
    "# 히스토리에 추가\n",
    "history.append({\"question\": query, \"answer\": response})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "경제 전문가 챗봇에 오신 것을 환영합니다!\n",
      "\n",
      "[챗봇 답변]:\n",
      " 안녕하세요! 경제 전문가 AI로서 여러분을 도와드릴 수 있습니다. 이전에 제공된 정보를 바탕으로 최근 월간산업동향 월호들을 살펴보았습니다. 2024년 9월호, 5월호, 6월호, 1월호, 11월호에 대한 데이터가 있습니다. 이러한 월간산업동향 자료를 통해 우리는 특정 산업의 동향을 파악하고 비교할 수 있습니다. \n",
      "\n",
      "예를 들어, 2024년 9월호와 11월호를 비교해보면 해당 기간 동안 산업의 성장 또는 하락 추세를 확인할 수 있습니다. 또한, 5월호와 6월호를 비교하여 특정 시기에 어떤 변화가 있었는지 분석할 수도 있습니다. 이러한 데이터를 통해 산업의 흐름을 이해하고 향후 전략을 수립하는 데 도움을 줄 수 있습니다.\n",
      "\n",
      "더 깊은 분석을 위해서는 각 월간산업동향의 세부 내용을 살펴보고 특정 산업군이나 기업의 동향을 파악해야 합니다. 이를 통해 경제 상황을 보다 정확하게 이해하고 투자나 경영에 대한 결정을 내릴 수 있습니다. 부족한 정보나 추가 질문이 있으시면 언제든지 물어보세요!\n",
      "챗봇을 종료합니다. 감사합니다!\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "# LLM 초기화\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "# 사용자 정의 프롬프트 템플릿\n",
    "custom_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\", \"history\"],\n",
    "    template=(\n",
    "        \"당신은 친절하고 전문적인 경제 전문가로서 사용자 질문에 답변하는 AI입니다. \"\n",
    "        \"당신의 목표는 복잡한 경제 정보를 쉽게 설명하고, 상세하고 정확하며 실용적인 조언을 제공하는 것입니다.\\n\\n\"\n",
    "        \"다음은 문서에서 추출한 관련 정보입니다:\\n\\n{context}\\n\\n\"\n",
    "        \"이전에 나눈 대화는 다음과 같습니다:\\n{history}\\n\\n\"\n",
    "        \"위의 정보와 대화를 바탕으로, 아래 질문에 대해 경제 전문가로서 \"\n",
    "        \"심층적이고 분석적인 답변을 작성해 주세요. \"\n",
    "        \"가능한 경우, 구체적인 예시와 설명을 추가하고, 관련 배경 지식도 포함해 주세요.\\n\\n\"\n",
    "        \"질문: {question}\\n\\n\"\n",
    "        \"친절하고 분석적인 답변:\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# QA 체인 생성\n",
    "qa_chain = create_stuff_documents_chain(llm, custom_prompt)\n",
    "\n",
    "# 대화 기록을 관리하는 클래스\n",
    "class ConversationHistory:\n",
    "    def __init__(self):\n",
    "        self.history = []\n",
    "\n",
    "    def add_entry(self, question, answer):\n",
    "        self.history.append({\"question\": question, \"answer\": answer})\n",
    "\n",
    "    def to_text(self):\n",
    "        return \"\\n\".join(\n",
    "            [f\"Q: {entry['question']}\\nA: {entry['answer']}\" for entry in self.history]\n",
    "        )\n",
    "\n",
    "# 히스토리 관리 객체 생성\n",
    "history_manager = ConversationHistory()\n",
    "\n",
    "# 사용자 질문 처리 함수\n",
    "def process_query(query):\n",
    "    # 유사 문서 검색\n",
    "    try:\n",
    "        retrieved_docs = vector_store.similarity_search(query, k=5)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during document retrieval: {e}\")\n",
    "        return \"문서를 검색하는 동안 오류가 발생했습니다.\"\n",
    "\n",
    "    # 검색된 문서를 Document 객체로 변환\n",
    "    documents = [\n",
    "        Document(\n",
    "            page_content=doc.page_content if hasattr(doc, 'page_content') else str(doc),\n",
    "            metadata=doc.metadata\n",
    "        )\n",
    "        for doc in retrieved_docs\n",
    "    ]\n",
    "\n",
    "    # 히스토리를 문자열로 생성\n",
    "    history_text = history_manager.to_text()\n",
    "\n",
    "    # 응답 생성\n",
    "    try:\n",
    "        response = qa_chain.invoke({\n",
    "            \"context\": documents,\n",
    "            \"question\": query,\n",
    "            \"history\": history_text\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error during response generation: {e}\")\n",
    "        response = \"응답을 생성하는 동안 오류가 발생했습니다.\"\n",
    "\n",
    "    # 히스토리에 추가\n",
    "    history_manager.add_entry(query, response)\n",
    "\n",
    "    return response\n",
    "\n",
    "# 예제 실행\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"경제 전문가 챗봇에 오신 것을 환영합니다!\")\n",
    "    while True:\n",
    "        query = input(\"질문을 입력하세요 (종료하려면 'exit' 입력): \")\n",
    "        if query.lower() == \"exit\":\n",
    "            print(\"챗봇을 종료합니다. 감사합니다!\")\n",
    "            break\n",
    "\n",
    "        response = process_query(query)\n",
    "        print(\"\\n[챗봇 답변]:\\n\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
