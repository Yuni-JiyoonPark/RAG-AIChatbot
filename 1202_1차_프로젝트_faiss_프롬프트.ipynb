{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8860\\1358860312.py:55: LangChainDeprecationWarning: This class is deprecated. See the following migration guides for replacements based on `chain_type`:\n",
      "stuff: https://python.langchain.com/docs/versions/migrating_chains/stuff_docs_chain\n",
      "map_reduce: https://python.langchain.com/docs/versions/migrating_chains/map_reduce_chain\n",
      "refine: https://python.langchain.com/docs/versions/migrating_chains/refine_chain\n",
      "map_rerank: https://python.langchain.com/docs/versions/migrating_chains/map_rerank_docs_chain\n",
      "\n",
      "See also guides on retrieval and question-answering here: https://python.langchain.com/docs/how_to/#qa-with-rag\n",
      "  qa_chain = load_qa_chain(llm, chain_type=\"stuff\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_openai import OpenAI, OpenAIEmbeddings\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# OpenAI API 키 설정 (환경 변수 사용 권장)\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "\n",
    "\n",
    "current_path = os.getcwd()\n",
    "index_folder_path = os.path.join(current_path, 'faiss_index')\n",
    "\n",
    "# 폴더 경로 지정\n",
    "folder_path = \"./reports\"\n",
    "\n",
    "# 문서 분할 설정\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "\n",
    "# 임베딩 모델 설정\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "if os.path.exists(index_folder_path):\n",
    "    vector_store = FAISS.load_local(index_folder_path,embeddings,allow_dangerous_deserialization=True)\n",
    "else : \n",
    "    # 전체 문서 저장소 초기화\n",
    "    all_docs = []\n",
    "\n",
    "    # 폴더 및 하위 폴더 내 PDF 파일 반복 처리\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file_name in files:\n",
    "            if file_name.endswith(\".pdf\"):\n",
    "                file_path = os.path.join(root, file_name)\n",
    "                print(f\"Processing file: {file_path}\")\n",
    "\n",
    "                # PDF 로더로 문서 읽기\n",
    "                loader = PyPDFLoader(file_path)\n",
    "                documents = loader.load()\n",
    "\n",
    "                # 문서 분할 및 추가\n",
    "                docs = text_splitter.split_documents(documents)\n",
    "                all_docs.extend(docs)\n",
    "\n",
    "\n",
    "\n",
    "    # 모든 문서를 벡터 저장소에 저장\n",
    "    vector_store = FAISS.from_documents(all_docs, embeddings)\n",
    "\n",
    "# LLM 설정\n",
    "llm = OpenAI(temperature=0)\n",
    "MODEL_NAME = \"gpt-4o\"\n",
    "\n",
    "# QA 체인 생성\n",
    "qa_chain = load_qa_chain(llm, chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS 저장소가 ./faiss_index에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 생성된 FAISS 저장소를 로컬에 저장\n",
    "save_path = \"./faiss_index\"\n",
    "vector_store.save_local(save_path)\n",
    "print(f\"FAISS 저장소가 {save_path}에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8860\\2063147431.py:7: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(temperature=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "약한 농업 부문에 적합한 금융 서비스 샘플을 제안하기 위해서는 해당 부문의 특징과 요구사항을 고려해야 합니다. \n",
      "\n",
      "농업 부문은 일반적으로 현금흐름이 계절적으로 변동하고, 예기치 못한 자연재해나 시장 변동에 취약한 특성을 가지고 있습니다. 따라서, 이러한 부분을 고려하여 다음과 같은 금융 서비스 샘플을 제안할 수 있습니다:\n",
      "\n",
      "1. 유동성 지원: 농업 부문에서는 수확기 등 특정 시기에 현금이 필요한 경우가 많습니다. 따라서, 유동성 지원을 위한 단기 대출 상품을 제공할 수 있습니다. 이를 통해 농업인들이 생산 활동을 원활하게 진행할 수 있도록 도와줄 수 있습니다.\n",
      "\n",
      "2. 보험 상품: 농업 부문은 자연재해에 취약한 특성을 가지고 있기 때문에, 보험 상품을 통해 농작물 손실이나 기타 위험에 대비할 수 있도록 도와줄 수 있습니다. 예를 들어, 폭우나 가뭄으로 인한 수확량 감소에 대비한 농작물 보험 상품을 제공할 수 있습니다.\n",
      "\n",
      "3. 교육 및 자문 서비스: 농업 부문은 기술력과 경영 능력이 중요한 요소입니다. 따라서, 농업인들에게 경영 및 기술 교육을 제공하고, 전문가의 자문을 받을 수 있는 서비스를 제공할 수 있습니다. 이를 통해 농업 생산성을 향상시키고 지속 가능한 농업 경영을 돕는데 도움이 될 수 있습니다.\n",
      "\n",
      "이러한 금융 서비스 샘플을 통해 약한 농업 부문에 대한 지원을 강화하고, 농업인들의 경영 안정성과 수익성을 향상시킬 수 있습니다. 추가적으로, 정부와 협력하여 지역 농업 발전을 위한 정책적 지원도 고려할 필요가 있습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "# LLM 초기화\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "# 사용자 정의 프롬프트 템플릿\n",
    "custom_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\", \"history\"],\n",
    "    template=(\n",
    "        \"다음은 문서에서 추출한 관련 정보입니다:\\n\\n{context}\\n\\n\"\n",
    "        \"이전에 나눈 대화는 다음과 같습니다:\\n{history}\\n\\n\"\n",
    "        \"위의 정보와 대화를 바탕으로, 아래 질문에 대해 깊이 있고 상세한 답변을 작성해 주세요.\\n\"\n",
    "        \"가능한 경우, 구체적인 예시와 설명을 추가하고, 관련 배경 지식도 포함해 주세요.\\n\\n\"\n",
    "        \"질문: {question}\\n\\n\"\n",
    "        \"상세하고 분석적인 답변:\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# QA 체인 생성\n",
    "qa_chain = create_stuff_documents_chain(llm, custom_prompt)\n",
    "\n",
    "# 사용자 질문 처리\n",
    "query = \"약한 농업 부문에 적합한 금융 서비스 샘플 제안\"\n",
    "\n",
    "# 유사 문서 검색\n",
    "retrieved_docs = vector_store.similarity_search(query, k=5)\n",
    "\n",
    "# 검색된 문서를 Document 객체로 변환 (page_content를 문자열로 설정)\n",
    "documents = [\n",
    "    Document(page_content=doc.page_content if hasattr(doc, 'page_content') else str(doc), metadata=doc.metadata)\n",
    "    for doc in retrieved_docs\n",
    "]\n",
    "\n",
    "# 히스토리 초기화\n",
    "history = []\n",
    "\n",
    "# 히스토리를 문자열로 생성\n",
    "history_text = \"\\n\".join(\n",
    "    [f\"Q: {entry['question']}\\nA: {entry['answer']}\" for entry in history]\n",
    ")\n",
    "\n",
    "# 응답 생성\n",
    "response = qa_chain.invoke({\n",
    "    \"context\": documents,\n",
    "    \"question\": query,\n",
    "    \"history\": history_text\n",
    "})\n",
    "\n",
    "# 출력\n",
    "print(response)\n",
    "\n",
    "# 히스토리에 추가\n",
    "history.append({\"question\": query, \"answer\": response})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "경제 전문가 챗봇에 오신 것을 환영합니다!\n",
      "\n",
      "[챗봇 답변]:\n",
      " 안녕하세요! 경제 전문가 AI입니다. 안부를 물어주셔서 감사합니다. 현재 경제 상황에 대해 궁금하신 점이 있으시면 언제든지 질문해 주세요. 최근 월간산업동향 보고서를 통해 2024년 1월, 5월, 6월, 9월, 11월의 산업 동향을 분석하고 있습니다. 이러한 데이터를 토대로 경제 동향을 예측하거나 특정 산업 분야에 대한 분석을 제공할 수 있습니다. 어떤 주제에 대해 더 자세히 알고 싶으신가요?\n",
      "\n",
      "[챗봇 답변]:\n",
      " 2025년 산업은행의 사업전망은 중국제조 2025 정책의 영향을 받을 것으로 예상됩니다. 이 정책은 정부 역할 축소와 시장 역할 확대를 중심으로 한 산업 발전 방향을 제시하고 있습니다. 산업은행은 이러한 정책 변화에 적극적으로 대응하여 시스템 개혁, 공정 경쟁 시장환경 조성, 금융 지원 정책 강화, 대외 개방 확대 등을 통해 산업 발전을 지원할 것으로 예상됩니다.\n",
      "\n",
      "예를 들어, 산업은행은 제조업 융자 채널을 확대하고, 제조업 발전에 적합한 보험 상품과 서비스를 개발하여 첨단기술기업의 성장을 촉진할 것으로 예상됩니다. 또한, 중소기업 정책의 개선을 통해 중소기업에 금융리스 및 지식재산권 담보 대출을 확대하여 중소기업의 경쟁력을 강화할 것으로 전망됩니다.\n",
      "\n",
      "산업은행은 또한 외국인 투자 유치를 위해 내국민 대우를 강화하고, 비즈니스 환경을 투명화하여 시장 진입장벽을 완화할 것으로 예상됩니다. 이러한 전략적인 방향성을 통해 2025년 산업은행은 중국의 제조업 발전을 지원하고 경제 성장에 기여할 것으로 기대됩니다.\n",
      "\n",
      "[챗봇 답변]:\n",
      " 산업은행의 취약한 산업은 주로 제조업과 관련된 부분으로 예상됩니다. 최근 산업은행의 사업전망을 분석한 결과, 부동산·건설업과 코로나 피해업종에 대한 대출이 늘어나는 반면 제조업의 비중이 축소되고 있다는 점이 관측되었습니다. 특히 코로나 팬데믹으로 인한 제조업의 생산 및 수요 감소, 그리고 해외 시장에서의 경쟁력 약화 등이 산업은행의 취약성을 높일 수 있습니다.\n",
      "\n",
      "제조업은 전통적으로 산업은행의 주요 대출 대상 중 하나였지만, 최근에는 코로나 사태와 글로벌 경제 상황 변화로 인해 제조업의 경쟁력이 약화되고 있습니다. 또한, 산업은행이 주로 중소기업을 대상으로 하는 특성상, 중소기업의 제조업체들이 경기 침체로 어려움을 겪고 있을 가능성이 있습니다.\n",
      "\n",
      "따라서, 산업은행은 제조업 부문의 변화와 취약성을 인식하고, 이를 극복하기 위한 적극적인 대책을 마련해야 할 것입니다. 예를 들어, 제조업체들의 디지털화 및 혁신을 지원하고, 글로벌 시장 진출을 돕는 프로그램을 개선하는 등의 방안을 고려할 수 있습니다. 또한, 산업은행은 제조업체들의 재무 건전성을 지원하고, 새로운 시장 확대를 위한 금융 지원을 강화하는 등의 노력이 필요할 것으로 보입니다.\n",
      "챗봇을 종료합니다. 감사합니다!\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "# LLM 초기화\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "# 사용자 정의 프롬프트 템플릿\n",
    "custom_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\", \"history\"],\n",
    "    template=(\n",
    "        \"당신은 친절하고 전문적인 경제 전문가로서 사용자 질문에 답변하는 AI입니다. \"\n",
    "        \"당신의 목표는 복잡한 경제 정보를 쉽게 설명하고, 상세하고 정확하며 실용적인 조언을 제공하는 것입니다.\\n\\n\"\n",
    "        \"다음은 문서에서 추출한 관련 정보입니다:\\n\\n{context}\\n\\n\"\n",
    "        \"이전에 나눈 대화는 다음과 같습니다:\\n{history}\\n\\n\"\n",
    "        \"위의 정보와 대화를 바탕으로, 아래 질문에 대해 경제 전문가로서 \"\n",
    "        \"심층적이고 분석적인 답변을 작성해 주세요. \"\n",
    "        \"가능한 경우, 구체적인 예시와 설명을 추가하고, 관련 배경 지식도 포함해 주세요.\\n\\n\"\n",
    "        \"질문: {question}\\n\\n\"\n",
    "        \"친절하고 분석적인 답변:\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# QA 체인 생성\n",
    "qa_chain = create_stuff_documents_chain(llm, custom_prompt)\n",
    "\n",
    "# 대화 기록을 관리하는 클래스\n",
    "class ConversationHistory:\n",
    "    def __init__(self):\n",
    "        self.history = []\n",
    "\n",
    "    def add_entry(self, question, answer):\n",
    "        self.history.append({\"question\": question, \"answer\": answer})\n",
    "\n",
    "    def to_text(self):\n",
    "        return \"\\n\".join(\n",
    "            [f\"Q: {entry['question']}\\nA: {entry['answer']}\" for entry in self.history]\n",
    "        )\n",
    "\n",
    "# 히스토리 관리 객체 생성\n",
    "history_manager = ConversationHistory()\n",
    "\n",
    "# 사용자 질문 처리 함수\n",
    "def process_query(query):\n",
    "    # 유사 문서 검색\n",
    "    try:\n",
    "        retrieved_docs = vector_store.similarity_search(query, k=5)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during document retrieval: {e}\")\n",
    "        return \"문서를 검색하는 동안 오류가 발생했습니다.\"\n",
    "\n",
    "    # 검색된 문서를 Document 객체로 변환\n",
    "    documents = [\n",
    "        Document(\n",
    "            page_content=doc.page_content if hasattr(doc, 'page_content') else str(doc),\n",
    "            metadata=doc.metadata\n",
    "        )\n",
    "        for doc in retrieved_docs\n",
    "    ]\n",
    "\n",
    "    # 히스토리를 문자열로 생성\n",
    "    history_text = history_manager.to_text()\n",
    "\n",
    "    # 응답 생성\n",
    "    try:\n",
    "        response = qa_chain.invoke({\n",
    "            \"context\": documents,\n",
    "            \"question\": query,\n",
    "            \"history\": history_text\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error during response generation: {e}\")\n",
    "        response = \"응답을 생성하는 동안 오류가 발생했습니다.\"\n",
    "\n",
    "    # 히스토리에 추가\n",
    "    history_manager.add_entry(query, response)\n",
    "\n",
    "    return response\n",
    "\n",
    "# 예제 실행\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"경제 전문가 챗봇에 오신 것을 환영합니다!\")\n",
    "    while True:\n",
    "        query = input(\"질문을 입력하세요 (종료하려면 'exit' 입력): \")\n",
    "        if query.lower() == \"exit\":\n",
    "            print(\"챗봇을 종료합니다. 감사합니다!\")\n",
    "            break\n",
    "\n",
    "        response = process_query(query)\n",
    "        print(\"\\n[챗봇 답변]:\\n\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
